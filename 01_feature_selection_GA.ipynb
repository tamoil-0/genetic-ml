{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Bloque 1 — Feature Selection con GA\nUsa **DEAP** + **LogisticRegression** con CV.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from utils.data import load_data\nfrom utils.ga_tools import set_seed, cv_score, penalty_k\nimport numpy as np\nimport random, os, joblib, matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom deap import base, creator, tools\n\nset_seed(42)\nX_train, X_test, y_train, y_test, feature_names = load_data()\nn_features = X_train.shape[1]\nn_features"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Configuración del GA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "POP_SIZE = 50\nN_GEN = 50\nCX_PB = 0.8\nMUT_PB = 0.2\nINDPB = 0.05\nTOUR_SIZE = 3\nALPHA = 0.005\nELITISM = 1\n\ndef make_estimator():\n    return LogisticRegression(max_iter=2000, solver='lbfgs')\n\ndef ensure_one_active(individual):\n    if sum(individual) == 0:\n        idx = random.randrange(len(individual))\n        individual[idx] = 1\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## DEAP: espacio de búsqueda y fitness"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\ncreator.create('Individual', list, fitness=creator.FitnessMax)\n\ntoolbox = base.Toolbox()\ntoolbox.register('attr_bool', random.randint, 0, 1)\ntoolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_features)\ntoolbox.register('population', tools.initRepeat, list, toolbox.individual)\n\ndef eval_individual(individual):\n    ensure_one_active(individual)\n    mask = np.array(individual, dtype=bool)\n    k = int(mask.sum())\n    X_sel = X_train[:, mask]\n    est = make_estimator()\n    acc = cv_score(est, X_sel, y_train, cv=5, scoring='accuracy', random_state=42)\n    fit = acc - penalty_k(k, ALPHA)\n    return (fit,)\n\ntoolbox.register('evaluate', eval_individual)\ntoolbox.register('mate', tools.cxOnePoint)\ntoolbox.register('mutate', tools.mutFlipBit, indpb=INDPB)\ntoolbox.register('select', tools.selTournament, tournsize=TOUR_SIZE)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Evolución"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "pop = toolbox.population(n=POP_SIZE)\nhof = tools.HallOfFame(ELITISM)\n\ndef pop_stats(p):\n    fits = [ind.fitness.values[0] for ind in p]\n    return float(np.mean(fits)), float(np.min(fits)), float(np.max(fits))\n\nfor ind in pop:\n    ind.fitness.values = toolbox.evaluate(ind)\n\nlog = []\nfor gen in range(N_GEN):\n    elites = tools.selBest(pop, ELITISM) if ELITISM > 0 else []\n    offspring = toolbox.select(pop, len(pop) - ELITISM)\n    offspring = list(map(toolbox.clone, offspring))\n    for i in range(0, len(offspring), 2):\n        if i+1 < len(offspring) and random.random() < CX_PB:\n            toolbox.mate(offspring[i], offspring[i+1])\n            del offspring[i].fitness.values, offspring[i+1].fitness.values\n    for i in range(len(offspring)):\n        if random.random() < MUT_PB:\n            toolbox.mutate(offspring[i])\n            del offspring[i].fitness.values\n    invalid = [ind for ind in offspring if not ind.fitness.valid]\n    for ind in invalid:\n        ind.fitness.values = toolbox.evaluate(ind)\n    pop = elites + offspring\n    avg, mn, mx = pop_stats(pop)\n    log.append({'gen': gen+1, 'avg': avg, 'min': mn, 'max': mx})\n\nbest = tools.selBest(pop, 1)[0]\nbest_mask = np.array(best, dtype=bool)\nbest_k = int(best_mask.sum())\nbest_fitness = float(best.fitness.values[0])\nbest_k, best_fitness"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Resultados y comparación"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "est_base = LogisticRegression(max_iter=2000, solver='lbfgs')\nbaseline_cv = cv_score(est_base, X_train, y_train, cv=5, scoring='accuracy', random_state=42)\nX_sel = X_train[:, best_mask]\nest_sel = LogisticRegression(max_iter=2000, solver='lbfgs')\nselected_cv = cv_score(est_sel, X_sel, y_train, cv=5, scoring='accuracy', random_state=42)\nselected_features = list(feature_names[best_mask])\nprint(f'Features seleccionadas (k={best_k}):')\nfor f in selected_features:\n    print('-', f)\nprint(f'Baseline CV accuracy (todas): {baseline_cv:.4f}')\nprint(f'Seleccionadas CV accuracy:   {selected_cv:.4f}')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Curva de mejor fitness por generación"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "gens = [r['gen'] for r in log]\nbest_curve = [r['max'] for r in log]\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.plot(gens, best_curve, marker='o')\nplt.xlabel('Generación')\nplt.ylabel('Mejor fitness')\nplt.title('Evolución del mejor fitness')\nplt.grid(True)\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Guardado opcional con joblib"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os, joblib\nos.makedirs('results', exist_ok=True)\nout = {\n    'best_mask': best_mask,\n    'selected_features': selected_features,\n    'best_fitness': best_fitness,\n    'baseline_cv': baseline_cv,\n    'selected_cv': selected_cv,\n    'log': log,\n}\njoblib.dump(out, 'results/bloque1_selection.joblib')\n\"Guardado en results/bloque1_selection.joblib\""
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}